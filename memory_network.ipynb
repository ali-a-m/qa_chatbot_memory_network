{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"memory_network.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMNNqhsVJHZ5J39gt5Sei84"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IsJqz4qWT6sx","executionInfo":{"status":"ok","timestamp":1607505669563,"user_tz":-210,"elapsed":2857,"user":{"displayName":"ali aminian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggazyt5exSIEUEMUQGdYjtiybnvL-MnWQcqM31m=s64","userId":"04260769914883903640"}}},"source":["import numpy as np\r\n","import tensorflow as tf\r\n","import datetime\r\n","import os\r\n","import re\r\n","import tarfile\r\n","import functools\r\n","\r\n","from sklearn.feature_extraction.text import CountVectorizer\r\n","from tensorflow.keras.preprocessing.text import Tokenizer\r\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n","from tensorflow.keras.models import Model, Sequential\r\n","from tensorflow.keras.layers import Dropout, Activation, Dense, LSTM, Input, Add, Dot, concatenate, Embedding, Permute"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wSaWn9Uqnb5O","executionInfo":{"status":"ok","timestamp":1607505670124,"user_tz":-210,"elapsed":3409,"user":{"displayName":"ali aminian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggazyt5exSIEUEMUQGdYjtiybnvL-MnWQcqM31m=s64","userId":"04260769914883903640"}},"outputId":"ef262dae-8385-4ecf-af83-e975c4d4da2e"},"source":["device_name = tf.test.gpu_device_name()\r\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wdm0TpuBgYHH"},"source":["### import data"]},{"cell_type":"code","metadata":{"id":"QI_4-Ei0idce","executionInfo":{"status":"ok","timestamp":1607505670125,"user_tz":-210,"elapsed":3402,"user":{"displayName":"ali aminian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggazyt5exSIEUEMUQGdYjtiybnvL-MnWQcqM31m=s64","userId":"04260769914883903640"}}},"source":["def tokenize(line):\r\n","\tline = re.sub(r'[^a-zA-Z]', ' ', line)\r\n","\tline = line.replace('   ', ' ').replace('  ', ' ')\r\n","\r\n","\treturn line\r\n","\r\n","def parse_stories(lines, only_supporting=False):\r\n","\tdata = []\r\n","\tstory = []\r\n","\r\n","\tfor line in lines:\r\n","\t\tline = line.decode('utf-8')\r\n","\t\tline = line.strip()\r\n","\r\n","\t\tnid, line = line.split(' ', 1)\r\n","\t\tnid = int(nid)\r\n","\r\n","\t\tif nid == 1:\r\n","\t\t\tstory = []\r\n","\t\tif '\\t' in line:\r\n","\t\t\tq, a, sp = line.split('\\t')\r\n","\t\t\tq = tokenize(q)\r\n","\r\n","\t\t\tsubstory = None\r\n","\r\n","\t\t\tif only_supporting:\r\n","\t\t\t\tsp = map(int, sp.split())\r\n","\t\t\t\tsubstory = [story[i - 1] for i in sp]\r\n","\r\n","\t\t\telse:\r\n","\t\t\t\tsubstory = [x for x in story if x]\r\n","\r\n","\t\t\tdata.append((substory, q, a))\r\n","\t\t\tstory.append('')\r\n","\r\n","\t\telse:\r\n","\t\t\tsent = tokenize(line)\r\n","\t\t\tstory.append(sent)\r\n","\r\n","\treturn data\r\n","\r\n","def get_stories(path, only_supporting=False):\r\n","\r\n","    data = parse_stories(path.readlines(), only_supporting=only_supporting)\r\n","    flatten = lambda data: functools.reduce(lambda x, y: x + y, data)\r\n","    data = [(flatten(story), q, a) for story, q, a in data]\r\n","    return data"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1mxLV_73gFlr","executionInfo":{"status":"ok","timestamp":1607505671157,"user_tz":-210,"elapsed":4427,"user":{"displayName":"ali aminian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggazyt5exSIEUEMUQGdYjtiybnvL-MnWQcqM31m=s64","userId":"04260769914883903640"}},"outputId":"981326f6-de3c-420d-9d0a-32fe8c3c0aed"},"source":["path = tf.keras.utils.get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\r\n","\r\n","tar = tarfile.open(path)\r\n","\r\n","challenges = {\r\n","    # QA1 with 10,000 samples\r\n","    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt',\r\n","    # QA2 with 10,000 samples\r\n","    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt',\r\n","}\r\n","challenge_type = 'single_supporting_fact_10k'\r\n","challenge = challenges[challenge_type]\r\n","\r\n","print('Extracting stories for the challenge:', challenge_type)\r\n","# train_inputs, train_queries, train_answers = get_stories(tar.extractfile(challenge.format('train')))\r\n","# test_inputs, test_queries, test_answers = get_stories(tar.extractfile(challenge.format('test')))\r\n","\r\n","train = get_stories(tar.extractfile(challenge.format('train')), only_supporting=True)\r\n","test = get_stories(tar.extractfile(challenge.format('test')), only_supporting=True)\r\n","\r\n","print('train size: {}, test size: {}'.format(len(train), len(test)))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Extracting stories for the challenge: single_supporting_fact_10k\n","train size: 10000, test size: 1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3hTDkqYyat3","executionInfo":{"status":"ok","timestamp":1607505671158,"user_tz":-210,"elapsed":4422,"user":{"displayName":"ali aminian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggazyt5exSIEUEMUQGdYjtiybnvL-MnWQcqM31m=s64","userId":"04260769914883903640"}},"outputId":"e921c7ca-91ea-4908-959d-a546cbcc8a1f"},"source":["for i in np.random.randint(0, 10000, size=3):\r\n","    print('+'*30)\r\n","    print(train[i])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["++++++++++++++++++++++++++++++\n","('Mary went back to the kitchen ', 'Where is Mary ', 'kitchen')\n","++++++++++++++++++++++++++++++\n","('Sandra travelled to the kitchen ', 'Where is Sandra ', 'kitchen')\n","++++++++++++++++++++++++++++++\n","('Daniel went to the hallway ', 'Where is Daniel ', 'hallway')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5YHHzRpmj--6","executionInfo":{"status":"ok","timestamp":1607505671608,"user_tz":-210,"elapsed":4865,"user":{"displayName":"ali aminian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggazyt5exSIEUEMUQGdYjtiybnvL-MnWQcqM31m=s64","userId":"04260769914883903640"}}},"source":["def tokenize_data(data):\r\n","    corpus = [' '.join((s, q, a)) for s,q,a in data]\r\n","\r\n","    tokenizer = Tokenizer(filters='')\r\n","    tokenizer.fit_on_texts(corpus)\r\n","\r\n","    return tokenizer\r\n","\r\n","tokenizer = tokenize_data(train+test)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YV1sjUvqkO-N","executionInfo":{"status":"ok","timestamp":1607505671609,"user_tz":-210,"elapsed":4861,"user":{"displayName":"ali aminian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggazyt5exSIEUEMUQGdYjtiybnvL-MnWQcqM31m=s64","userId":"04260769914883903640"}},"outputId":"345dd569-8cc8-4314-c136-65239e5a8e89"},"source":["vocab_size = len(tokenizer.word_index) + 1\r\n","story_maxlen = max(map(len, (x for x,_,_ in train+test)))\r\n","query_maxlen = max(map(len, (x for _,x,_ in train+test)))\r\n","# answer_maxlen = max(map(len, (x for _,_,x in train+test)))\r\n","answer_maxlen = vocab_size\r\n","\r\n","print('Vocab size:', vocab_size, 'unique words')\r\n","print('Story max length:', story_maxlen, 'words')\r\n","print('Query max length:', query_maxlen, 'words')\r\n","print('answer max length:', answer_maxlen, 'words')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Vocab size: 20 unique words\n","Story max length: 33 words\n","Query max length: 16 words\n","answer max length: 20 words\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7zfOJV-Ix4HX","executionInfo":{"status":"ok","timestamp":1607505671609,"user_tz":-210,"elapsed":4854,"user":{"displayName":"ali aminian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggazyt5exSIEUEMUQGdYjtiybnvL-MnWQcqM31m=s64","userId":"04260769914883903640"}},"outputId":"88e991c9-b76c-4aa7-dd06-33cb6f004f84"},"source":["def padding_data(data, story_maxlen, query_maxlen, answer_maxlen, tokenizer):\r\n","    story, ques, ans = [], [], []\r\n","\r\n","    word_idx = tokenizer.word_index\r\n","    \r\n","    for s, q, a in data:\r\n","        story.append(s)\r\n","        ques.append(q)\r\n","        \r\n","        y = np.zeros(len(word_idx)+1)\r\n","        y[word_idx[a]] = 1\r\n","        ans.append(y)\r\n","\r\n","    story_seq = tokenizer.texts_to_sequences(story)\r\n","    ques_seq = tokenizer.texts_to_sequences(ques)\r\n","    ans_seq = np.array(ans)\r\n","    \r\n","    return pad_sequences(story_seq, maxlen=story_maxlen), pad_sequences(ques_seq, maxlen=query_maxlen), ans_seq\r\n","\r\n","train_inputs, train_queries, train_answers = padding_data(train, story_maxlen, query_maxlen, answer_maxlen, tokenizer)\r\n","test_inputs, test_queries, test_answers = padding_data(test, story_maxlen, query_maxlen, answer_maxlen, tokenizer)\r\n","print(train_inputs.shape, train_queries.shape, train_answers.shape)\r\n","print(test_inputs.shape, test_queries.shape, test_answers.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(10000, 33) (10000, 16) (10000, 20)\n","(1000, 33) (1000, 16) (1000, 20)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4attn6wx16n1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607505672273,"user_tz":-210,"elapsed":5511,"user":{"displayName":"ali aminian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggazyt5exSIEUEMUQGdYjtiybnvL-MnWQcqM31m=s64","userId":"04260769914883903640"}},"outputId":"0990c664-3386-43e7-c2a2-b5c547fca4c5"},"source":["with tf.device('/device:GPU:0'):\r\n","    input_sequence = Input((story_maxlen,))\r\n","    question = Input((query_maxlen,))\r\n","\r\n","    #HyperParameters\r\n","    BATCH_SIZE = 32\r\n","    EPOCHS = 10\r\n","\r\n","    input_encoder_m = Sequential()\r\n","\r\n","    input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\r\n","    input_encoder_m.add(Dropout(0.3))\r\n","\r\n","    input_encoder_c = Sequential()\r\n","    input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=query_maxlen))\r\n","    input_encoder_c.add(Dropout(0.3))\r\n","\r\n","    question_encoder = Sequential()\r\n","    question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=query_maxlen))\r\n","    question_encoder.add(Dropout(0.3))\r\n","\r\n","    # encoder the input sequence\r\n","    input_encoded_m = input_encoder_m(input_sequence)\r\n","    input_encoded_c = input_encoder_c(input_sequence)\r\n","    question_encoded = question_encoder(question)\r\n","\r\n","    # print(input_encoded_m.shape, input_encoded_c.shape, question_encoded.shape)\r\n","\r\n","    # compute the match between input sequence and question sequence\r\n","    match = Dot(axes=(2,2))([input_encoded_m, question_encoded])\r\n","    match = Activation('softmax')(match)\r\n","\r\n","    # print('match shape:', match.shape)\r\n","\r\n","    response = Add()([match, input_encoded_c])\r\n","    response = Permute((2,1))(response)\r\n","\r\n","    # print('response shape:', response.shape)\r\n","\r\n","    answer = concatenate([response, question_encoded])\r\n","\r\n","    # print('after concat:', answer.shape)\r\n","\r\n","    answer = LSTM(64, activation='relu')(answer)\r\n","    answer = Dropout(0.3)(answer)\r\n","\r\n","    answer = Dense(answer_maxlen)(answer)\r\n","    answer = Activation('softmax')(answer)\r\n","\r\n","    # print('after core of model:', answer.shape)\r\n","\r\n","    model = Model([input_sequence, question], answer)\r\n","model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 33)]         0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 16)]         0                                            \n","__________________________________________________________________________________________________\n","sequential (Sequential)         (None, None, 64)     1280        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","sequential_2 (Sequential)       (None, 16, 64)       1280        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","dot (Dot)                       (None, 33, 16)       0           sequential[0][0]                 \n","                                                                 sequential_2[0][0]               \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 33, 16)       0           dot[0][0]                        \n","__________________________________________________________________________________________________\n","sequential_1 (Sequential)       (None, None, 16)     320         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 33, 16)       0           activation[0][0]                 \n","                                                                 sequential_1[0][0]               \n","__________________________________________________________________________________________________\n","permute (Permute)               (None, 16, 33)       0           add[0][0]                        \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 16, 97)       0           permute[0][0]                    \n","                                                                 sequential_2[0][0]               \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     (None, 64)           41472       concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 64)           0           lstm[0][0]                       \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 20)           1300        dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 20)           0           dense[0][0]                      \n","==================================================================================================\n","Total params: 45,652\n","Trainable params: 45,652\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zSICSOUb7FoM","executionInfo":{"status":"ok","timestamp":1607505810504,"user_tz":-210,"elapsed":143725,"user":{"displayName":"ali aminian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggazyt5exSIEUEMUQGdYjtiybnvL-MnWQcqM31m=s64","userId":"04260769914883903640"}},"outputId":"e4748a82-cf2d-409f-ad7d-ecde6909d34d"},"source":["with tf.device('/device:GPU:0'):\r\n","    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\r\n","\r\n","    history = model.fit([train_inputs, train_queries], train_answers,\r\n","        batch_size=BATCH_SIZE,\r\n","        epochs=EPOCHS,\r\n","        validation_data=([test_inputs, test_queries], test_answers)\r\n","    )"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","313/313 [==============================] - 14s 44ms/step - loss: 1.4079 - accuracy: 0.3979 - val_loss: 0.2379 - val_accuracy: 1.0000\n","Epoch 2/10\n","313/313 [==============================] - 14s 43ms/step - loss: 0.1819 - accuracy: 0.9536 - val_loss: 3.6848e-04 - val_accuracy: 1.0000\n","Epoch 3/10\n","313/313 [==============================] - 14s 43ms/step - loss: 0.0391 - accuracy: 0.9894 - val_loss: 4.3315e-04 - val_accuracy: 1.0000\n","Epoch 4/10\n","313/313 [==============================] - 14s 44ms/step - loss: 0.0253 - accuracy: 0.9949 - val_loss: 7.1749e-06 - val_accuracy: 1.0000\n","Epoch 5/10\n","313/313 [==============================] - 14s 43ms/step - loss: 0.0265 - accuracy: 0.9965 - val_loss: 5.5490e-06 - val_accuracy: 1.0000\n","Epoch 6/10\n","313/313 [==============================] - 13s 43ms/step - loss: 0.0166 - accuracy: 0.9973 - val_loss: 1.6337e-05 - val_accuracy: 1.0000\n","Epoch 7/10\n","313/313 [==============================] - 13s 43ms/step - loss: 0.0190 - accuracy: 0.9978 - val_loss: 2.7966e-07 - val_accuracy: 1.0000\n","Epoch 8/10\n","313/313 [==============================] - 14s 43ms/step - loss: 0.0330 - accuracy: 0.9987 - val_loss: 4.1485e-08 - val_accuracy: 1.0000\n","Epoch 9/10\n","313/313 [==============================] - 13s 43ms/step - loss: 0.0156 - accuracy: 0.9978 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n","Epoch 10/10\n","313/313 [==============================] - 14s 44ms/step - loss: 0.0219 - accuracy: 0.9982 - val_loss: 4.8500e-06 - val_accuracy: 1.0000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xFhkVEJHhrXl","executionInfo":{"status":"ok","timestamp":1607505810505,"user_tz":-210,"elapsed":143718,"user":{"displayName":"ali aminian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggazyt5exSIEUEMUQGdYjtiybnvL-MnWQcqM31m=s64","userId":"04260769914883903640"}}},"source":["def convert(tensor, tokenizer):\r\n","    idx_word = tokenizer.index_word\r\n","    string = ''\r\n","\r\n","    for i in tensor[0].numpy():\r\n","        if i == 0:\r\n","            continue\r\n","        string += idx_word[i] + ' '\r\n","\r\n","    return string"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPgr5NK5jilw","executionInfo":{"status":"ok","timestamp":1607505811072,"user_tz":-210,"elapsed":144280,"user":{"displayName":"ali aminian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggazyt5exSIEUEMUQGdYjtiybnvL-MnWQcqM31m=s64","userId":"04260769914883903640"}},"outputId":"959cb391-c359-4088-dadf-2df05840ff59"},"source":["for i in np.random.randint(0, len(test), size=10):\r\n","    query_text, story_text = tf.expand_dims(test_queries[i], 0), tf.expand_dims(test_inputs[i], 0)\r\n","    pre = model.predict((story_text, query_text))\r\n","\r\n","    valuemax = pre.argmax()\r\n","\r\n","    print('+'*50)\r\n","    print('story:', convert(story_text, tokenizer))\r\n","    print('question:', convert(query_text, tokenizer))\r\n","    print('answer:', tokenizer.index_word[valuemax])\r\n","    print('probability of the answer:', pre[0][valuemax])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["++++++++++++++++++++++++++++++++++++++++++++++++++\n","story: daniel went to the office \n","question: where is daniel \n","answer: office\n","probability of the answer: 1.0\n","++++++++++++++++++++++++++++++++++++++++++++++++++\n","story: john went back to the office \n","question: where is john \n","answer: office\n","probability of the answer: 1.0\n","++++++++++++++++++++++++++++++++++++++++++++++++++\n","story: mary travelled to the garden \n","question: where is mary \n","answer: garden\n","probability of the answer: 0.9999763\n","++++++++++++++++++++++++++++++++++++++++++++++++++\n","story: mary journeyed to the bathroom \n","question: where is mary \n","answer: bathroom\n","probability of the answer: 1.0\n","++++++++++++++++++++++++++++++++++++++++++++++++++\n","story: daniel journeyed to the kitchen \n","question: where is daniel \n","answer: kitchen\n","probability of the answer: 1.0\n","++++++++++++++++++++++++++++++++++++++++++++++++++\n","story: mary went back to the kitchen \n","question: where is mary \n","answer: kitchen\n","probability of the answer: 1.0\n","++++++++++++++++++++++++++++++++++++++++++++++++++\n","story: sandra went to the hallway \n","question: where is sandra \n","answer: hallway\n","probability of the answer: 1.0\n","++++++++++++++++++++++++++++++++++++++++++++++++++\n","story: daniel travelled to the bathroom \n","question: where is daniel \n","answer: bathroom\n","probability of the answer: 1.0\n","++++++++++++++++++++++++++++++++++++++++++++++++++\n","story: daniel travelled to the bedroom \n","question: where is daniel \n","answer: bedroom\n","probability of the answer: 0.9999999\n","++++++++++++++++++++++++++++++++++++++++++++++++++\n","story: mary journeyed to the office \n","question: where is mary \n","answer: office\n","probability of the answer: 1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9RaWwxh_5FqL"},"source":[""],"execution_count":null,"outputs":[]}]}